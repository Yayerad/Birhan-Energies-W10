{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"../src/data/merged_data.csv\", parse_dates=[\"Date\"], index_col=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 1. Data Preprocessing\n",
    "# --------------------------\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "\n",
    "# Split data into train and test\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data_scaled.iloc[:train_size], data_scaled.iloc[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. ARIMA Model\n",
    "# --------------------------\n",
    "arima_model = ARIMA(train[\"Price\"], order=(5,1,0)).fit()\n",
    "arima_pred = arima_model.forecast(steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      6,   Neg. LLF: 441576962561.84973\n",
      "Iteration:      2,   Func. Count:     16,   Neg. LLF: 71146720105.34631\n",
      "Iteration:      3,   Func. Count:     23,   Neg. LLF: 856978871.3776429\n",
      "Iteration:      4,   Func. Count:     29,   Neg. LLF: 10487.884962238506\n",
      "Iteration:      5,   Func. Count:     34,   Neg. LLF: 10304.295870362965\n",
      "Iteration:      6,   Func. Count:     46,   Neg. LLF: 9655.979252262961\n",
      "Iteration:      7,   Func. Count:     51,   Neg. LLF: 179770390409.35413\n",
      "Iteration:      8,   Func. Count:     66,   Neg. LLF: 753112.0553529745\n",
      "Iteration:      9,   Func. Count:     79,   Neg. LLF: 55849.04185920563\n",
      "Iteration:     10,   Func. Count:     94,   Neg. LLF: 10953.940485327956\n",
      "Iteration:     11,   Func. Count:     99,   Neg. LLF: 6559068.932206704\n",
      "Iteration:     12,   Func. Count:    106,   Neg. LLF: 1025108.5184233341\n",
      "Iteration:     13,   Func. Count:    112,   Neg. LLF: 10431.087184883369\n",
      "Iteration:     14,   Func. Count:    118,   Neg. LLF: 8860.671046357544\n",
      "Iteration:     15,   Func. Count:    124,   Neg. LLF: 9549.029865754466\n",
      "Iteration:     16,   Func. Count:    130,   Neg. LLF: 30500521037.736618\n",
      "Iteration:     17,   Func. Count:    144,   Neg. LLF: 12393.107507505025\n",
      "Iteration:     18,   Func. Count:    150,   Neg. LLF: 2130104861.0327222\n",
      "Iteration:     19,   Func. Count:    161,   Neg. LLF: 4110072076.883677\n",
      "Iteration:     20,   Func. Count:    168,   Neg. LLF: 8216.322990218381\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 8216.322980157347\n",
      "            Iterations: 24\n",
      "            Function evaluations: 168\n",
      "            Gradient evaluations: 20\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. GARCH Model\n",
    "# --------------------------\n",
    "scaled_price = train[\"Price\"] * 10  # Rescale Price\n",
    "garch_model = arch_model(scaled_price, vol='Garch', p=1, q=1, rescale=False).fit()\n",
    "garch_pred = garch_model.forecast(start=len(train), horizon=len(test)).variance.mean(axis=1) / 10  # Rescale back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 4. VAR Model\n",
    "# --------------------------\n",
    "var_model = VAR(train)\n",
    "var_fitted = var_model.fit(5)\n",
    "var_pred = var_fitted.forecast(train.values[-5:], steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5. Markov-Switching Model\n",
    "# --------------------------\n",
    "markov_model = MarkovRegression(train[\"Price\"], k_regimes=2, trend='c', switching_variance=True).fit()\n",
    "markov_pred = markov_model.smoothed_marginal_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator.MMCY\\OneDrive - MMCYTECH\\Desktop\\10a\\Birhan-Energies-W10\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0571\n",
      "Epoch 2/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.0648e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9.9402e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9.2388e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8.5305e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8.4879e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.6621e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.7379e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8.0521e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8.0833e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.2861e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.6979e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.5903e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.7969e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6.9624e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.1038e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.0599e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.0226e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.0058e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.9255e-05\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 6. LSTM Model\n",
    "# --------------------------\n",
    "X_train, y_train = train[\"Price\"].values[:-1], train[\"Price\"].values[1:]\n",
    "X_test, y_test = test[\"Price\"].values[:-1], test[\"Price\"].values[1:]\n",
    "X_train, X_test = X_train.reshape(-1,1,1), X_test.reshape(-1,1,1)\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(1,1)),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=1)\n",
    "lstm_pred = lstm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
